# Data Discovery
- Topic Analysis
  - Topical (dis-)similarity between authors
  - Making sure it is not turning into a topic classification task (balance is important)
  - Measure the difference between the two authors' topic probability distribution (using KL divergence).
- Style Analysis

# Classifier
- Adding a layer of emotional/sentiment analysis (if by using a different classifying method)
- Exploring POS
- Exploring the existence/frequency of NE
- Stylometric features include lexical, syntactic, structural, and content-specific features.
  - Transformers capture all those features. Should we contribute to adding concentration on a certain feature?
- Maybe we will need to split the large texts (to prevent bias towards large texts).
- We should experiment with little and much preprocessing.
- Can LLMs capture metaphorical expressions?
  - Measure the usage of metaphors for every author.
- Identify features that are meant to affect the style of the authors.
  - Topics
    - Locations/places
    - Female authors may be different
  - Metaphors
  - Lexicon Richness
  - Syntax/Structure Complexity
  - Text Length
  - Dialect Use
    - Classical Arabic vs MSA
- Augmenting Data for authors with less data
- Distinguishing between too similar authors
- We can benefit from dates the same way as we might benefit from locations/places.
- Choosing a model that absorbs dialect.
- If we combined BERT with CNN, we would enhance feature representation.
  - BERT's ability to capture rich contextual understanding of text and CNNs' proficiency in extracting local features and patterns from sequences.
- Go with the multimodal ensemble approach
- Try the boosting technique or bagging (ensemble with fully connected Bert models)
- Increasing weights for representative topics (clusters)
- Reclustering
- Trying generative models
